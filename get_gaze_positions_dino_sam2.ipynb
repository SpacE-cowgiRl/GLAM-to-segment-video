{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0df0a3b-55f3-40e5-ace9-45fe09dbba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from groundingdino.util.inference import Model\n",
    "from typing import List\n",
    "import os\n",
    "import supervision as sv\n",
    "import cv2\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO, SAM\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from sam2.build_sam import build_sam2, build_sam2_video_predictor\n",
    "import rerun as rr\n",
    "#from track_utils import sample_points_from_masks\n",
    "#from video_utils import create_video_from_images\n",
    "import json\n",
    "import random\n",
    "from uuid import uuid4\n",
    "import pandas as pd\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "000fc5fa-35b9-4312-a778-7b26ea18b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install supervision==0.22.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28e2671b-8d96-41eb-b53b-b8b32a4104af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bdd1836-566e-450c-a80c-6d6c34c7cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "loggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\n",
    "for logger in loggers:\n",
    "    if \"transformers\" in logger.name.lower():\n",
    "        logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68bd2e8b-2ae3-4fd5-ba50-b9c6b25a0ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLAMModel:\n",
    "    def __init__(self, grounding_dino_config_path, grounding_dino_checkpoint_path, sam_model_cfg, sam_checkpoint_path, prompt=None):\n",
    "        if prompt is None:\n",
    "            # prompt = ['pathways', 'trails', 'walkways', 'sidewalks', 'tracks', 'footpaths', 'routes', 'pedestrian paths', 'walking paths', 'lanes']\n",
    "            prompt = ['pavement', 'fence', 'cyclepath', 'trees', 'grasses', 'sidewalk', 'buildings', 'skies', 'streetlights']\n",
    "        self.prompt = prompt\n",
    "        self.grounding_dino_model = Model(model_config_path=grounding_dino_config_path, model_checkpoint_path=grounding_dino_checkpoint_path)\n",
    "        self.sam = build_sam2(sam_model_cfg, sam_checkpoint_path, device=\"cuda\")\n",
    "        self.sam_predictor = SAM2ImagePredictor(self.sam)\n",
    "        self.yolo = YOLO('yolov8x-seg.pt')\n",
    "        with open('class_descriptions.json', 'r', encoding='utf-8') as file:\n",
    "            self.class_names = json.load(file)\n",
    "\n",
    "        self.class_names += [{'id': 80+i, 'color': self.generate_random_color(), 'name': p} for i, p in enumerate(self.prompt)]\n",
    "        self.class_dict = {item['id']: item['name'] for item in self.class_names}\n",
    "        # self.dino_classes = 'pathways . trails . walkways'\n",
    "        self.dino_classes = self.enhance_class_name(self.prompt)\n",
    "        # self.dino_classes = str.join(' . ', self.prompt) + ' .'\n",
    "        self.dino_box_threshold = 0.35\n",
    "        self.dino_text_threshold = 0.25\n",
    "        self.class_descriptions = [rr.AnnotationInfo(id=cat[\"id\"], color=cat[\"color\"], label=cat[\"name\"]) for cat in self.class_names]\n",
    "        self.yolo_classes = [0, 1, 2, 3, 5, 7, 9, 11, 30]  \n",
    "        self.persist = []\n",
    "        self.video_outs = dict()\n",
    "        \n",
    "    @staticmethod\n",
    "    def enhance_class_name(class_names: List[str]) -> List[str]:\n",
    "        return [f\"{class_name}\" for class_name in class_names]\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_random_color():\n",
    "        r = random.randint(0, 255)\n",
    "        g = random.randint(0, 255)\n",
    "        b = random.randint(0, 255)\n",
    "        return r, g, b\n",
    "    \n",
    "    def add_dino_class(self, _phrase):\n",
    "        _class_id = max(self.class_dict.keys()) + 1\n",
    "        self.class_names.append({'id': _class_id, 'color': self.generate_random_color(), 'name': _phrase})\n",
    "        self.class_dict = {item['id']: item['name'] for item in self.class_names}\n",
    "        self.class_descriptions = [rr.AnnotationInfo(id=cat[\"id\"], color=cat[\"color\"], label=cat[\"name\"]) for cat in self.class_names]\n",
    "        return _class_id\n",
    "    \n",
    "    def dino_id_to_class_name(self, dino_id):\n",
    "        return self.class_dict[dino_id]\n",
    "    \n",
    "    def phrases2classes(self, phrases: List[str]) -> (np.ndarray, bool):\n",
    "        class_ids = []\n",
    "        ret = False\n",
    "        for phrase in phrases:\n",
    "            if phrase in self.class_dict.values():\n",
    "                for k, v in self.class_dict.items():\n",
    "                    if v == phrase:\n",
    "                        class_ids.append(k)\n",
    "            else:\n",
    "                _class_id = self.add_dino_class(phrase)\n",
    "                class_ids.append(_class_id)\n",
    "                ret = True\n",
    "        return np.array(class_ids), ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "092b708d-805f-484a-8027-95a9924bb4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUNDING_DINO_CONFIG_PATH = os.path.join('../', \"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\")\n",
    "GROUNDING_DINO_CHECKPOINT_PATH = os.path.join('../', \"weights\", \"groundingdino_swint_ogc.pth\")\n",
    "SAM_CHECKPOINT_PATH = os.path.join(\"/home/lnt/PycharmProjects/sam/weights/sam2_hiera_large.pt\")\n",
    "SAM_MODEL_CFG = \"sam2_hiera_l.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef9b1d86-a57f-4e60-bcb9-5add0a6ded09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 13077/13077 [1:11:40<00:00,  3.04it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 初始化 GLAMModel\n",
    "glam_model = GLAMModel(grounding_dino_config_path=GROUNDING_DINO_CONFIG_PATH, \n",
    "                       grounding_dino_checkpoint_path=GROUNDING_DINO_CHECKPOINT_PATH, \n",
    "                       sam_model_cfg=SAM_MODEL_CFG, \n",
    "                       sam_checkpoint_path=SAM_CHECKPOINT_PATH)\n",
    "\n",
    "# 加载 gaze 点数据\n",
    "gaze_data = pd.read_csv('/home/lnt/PycharmProjects/sam/data/gaze_positions.csv')\n",
    "\n",
    "# 初始化视频\n",
    "frame_pos = 0\n",
    "HOME = '/home/lnt/PycharmProjects/sam'\n",
    "SOURCE_VIDEO_PATH = f\"{HOME}/data/world_raw.mp4\"\n",
    "output_path = f\"{HOME}/data/video_dino-sam1_yolo_masks.mp4\"\n",
    "cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# 初始化一个新的DataFrame来保存结果\n",
    "results = []\n",
    "\n",
    "for frame_number in tqdm(range(frame_pos, total_frames)):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "\n",
    "    # 获取当前帧的 gaze 点\n",
    "    current_gaze_points = gaze_data[gaze_data['world_index'] == frame_number]\n",
    "\n",
    "    # Dino-SAM 预测\n",
    "    dino_results, phrases = glam_model.grounding_dino_model.predict_with_caption(\n",
    "        image=frame,\n",
    "        caption=str.join(' . ', glam_model.prompt),\n",
    "        box_threshold=glam_model.dino_box_threshold,\n",
    "        text_threshold=glam_model.dino_text_threshold\n",
    "    )\n",
    "    dino_results.class_id, ret = glam_model.phrases2classes(phrases)\n",
    "    \n",
    "    glam_model.sam_predictor.set_image(frame)\n",
    "\n",
    "    # 检查每个 gaze 点是否落在任何一个掩膜上\n",
    "    for _box, _cls_id, _confidence, _phrase in zip(dino_results.xyxy, dino_results.class_id, dino_results.confidence, phrases):\n",
    "        _masks, _scores, _logits = glam_model.sam_predictor.predict(\n",
    "            box=_box,\n",
    "            multimask_output=True\n",
    "        )\n",
    "        _index = np.argmax(_scores)\n",
    "        _mask = _masks[_index]\n",
    "        _mask = _mask.astype('bool')\n",
    "        \n",
    "        for _, gaze_point in current_gaze_points.iterrows():\n",
    "            # 获取 gaze 点的实际坐标\n",
    "            gaze_x = int(gaze_point['norm_pos_x'] * width)\n",
    "            gaze_y = int((1 - gaze_point['norm_pos_y']) * height)\n",
    "            \n",
    "            # 确保坐标在图像范围内\n",
    "            if 0 <= gaze_x < _mask.shape[1] and 0 <= gaze_y < _mask.shape[0]:\n",
    "                # 检查 gaze 点是否在掩膜内\n",
    "                if _mask[gaze_y, gaze_x]:\n",
    "                    # 记录结果\n",
    "                    results.append({\n",
    "                        'index': gaze_point.name,\n",
    "                        'timestamp': gaze_point['gaze_timestamp'],\n",
    "                        'frame': frame_number,\n",
    "                        'label': _phrase,\n",
    "                        'x': gaze_x,\n",
    "                        'y': gaze_y,\n",
    "                    })\n",
    "\n",
    "        # 注释和可视化（可选）\n",
    "        mask_result = sv.Detections(np.array([_box]), np.array([_mask]), np.array([_confidence]), np.array([_cls_id]))\n",
    "        mask_annotator = sv.MaskAnnotator()\n",
    "        box_annotator = sv.BoxAnnotator()\n",
    "        label_annotator = sv.LabelAnnotator(text_position=sv.Position.CENTER)\n",
    "        annotated_frame = mask_annotator.annotate(scene=annotated_frame, detections=mask_result)\n",
    "        annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=mask_result)\n",
    "        annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=mask_result, labels=[_phrase])\n",
    "    cv2.putText(annotated_frame, f'Frame: {frame_number}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    out.write(annotated_frame)\n",
    "    \n",
    "# 保存结果到 CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('/home/lnt/PycharmProjects/sam/data/dino_sam2_gazed.csv', index=False)\n",
    "\n",
    "out.release()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75130e21-fa7f-49ce-9a7b-00d02747031e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc4d9b-350a-4300-9254-b648c450b2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
