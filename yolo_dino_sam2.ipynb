{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T14:18:10.715948Z",
     "start_time": "2024-08-08T14:18:07.593407Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from groundingdino.util.inference import Model\n",
    "from typing import List\n",
    "import os\n",
    "import supervision as sv\n",
    "import cv2\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO, SAM\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from sam2.build_sam import build_sam2, build_sam2_video_predictor\n",
    "import rerun as rr\n",
    "#from track_utils import sample_points_from_masks\n",
    "#from video_utils import create_video_from_images\n",
    "import json\n",
    "import random\n",
    "from uuid import uuid4\n",
    "import pandas as pd\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b0fbcd4-7e6e-4f56-84b9-d98f11a7a2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: supervision==0.22.0 in /home/lnt/anaconda3/lib/python3.10/site-packages (0.22.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /home/lnt/anaconda3/lib/python3.10/site-packages (from supervision==0.22.0) (6.0.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /home/lnt/anaconda3/lib/python3.10/site-packages (from supervision==0.22.0) (0.7.1)\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in /home/lnt/anaconda3/lib/python3.10/site-packages (from supervision==0.22.0) (3.9.1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.5.5.64 in /home/lnt/anaconda3/lib/python3.10/site-packages (from supervision==0.22.0) (4.8.0.74)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/lnt/anaconda3/lib/python3.10/site-packages (from supervision==0.22.0) (1.26.4)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /home/lnt/anaconda3/lib/python3.10/site-packages (from supervision==0.22.0) (1.10.0)\n",
      "Requirement already satisfied: pillow>=9.4 in /home/lnt/anaconda3/lib/python3.10/site-packages (from supervision==0.22.0) (10.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/lnt/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision==0.22.0) (24.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/lnt/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision==0.22.0) (1.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/lnt/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision==0.22.0) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/lnt/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision==0.22.0) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/lnt/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision==0.22.0) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/lnt/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision==0.22.0) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/lnt/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision==0.22.0) (1.4.4)\n",
      "Requirement already satisfied: six in /home/lnt/anaconda3/lib/python3.10/site-packages (from cycler>=0.10->matplotlib>=3.6.0->supervision==0.22.0) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install supervision==0.22.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16dacc27-e36f-4c02-94c6-ccd481e07af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bfd96b6da01f270",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T14:18:11.540043Z",
     "start_time": "2024-08-08T14:18:11.536970Z"
    }
   },
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "loggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\n",
    "for logger in loggers:\n",
    "    if \"transformers\" in logger.name.lower():\n",
    "        logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "344c20cc98b8c491",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T15:50:29.159016Z",
     "start_time": "2024-08-08T15:50:29.155027Z"
    }
   },
   "outputs": [],
   "source": [
    "#video_folder = [f\"{i}\" for i in range(1, 14)]\n",
    "#video_paths = [os.path.join(f'/mnt/data/Datasets/Innsbruk/test/output_video_part_{f}.mp4') for f in video_folder]\n",
    "#video_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39f3fd55838b0d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T16:31:36.063572Z",
     "start_time": "2024-08-08T16:31:36.057043Z"
    }
   },
   "outputs": [],
   "source": [
    "class GLAMModel:\n",
    "    def __init__(self, grounding_dino_config_path, grounding_dino_checkpoint_path, sam_model_cfg, sam_checkpoint_path, prompt=None):\n",
    "        if prompt is None:\n",
    "            # prompt = ['pathways', 'trails', 'walkways', 'sidewalks', 'tracks', 'footpaths', 'routes', 'pedestrian paths', 'walking paths', 'lanes']\n",
    "            prompt = ['pavement', 'fence', 'cyclepath', 'trees', 'grasses', 'sidewalk', 'buildings', 'skies', 'streetlights']\n",
    "        self.prompt = prompt\n",
    "        self.grounding_dino_model = Model(model_config_path=grounding_dino_config_path, model_checkpoint_path=grounding_dino_checkpoint_path)\n",
    "        self.sam = build_sam2(sam_model_cfg, sam_checkpoint_path, device=\"cuda\")\n",
    "        self.sam_predictor = SAM2ImagePredictor(self.sam)\n",
    "        self.yolo = YOLO('yolov8x-seg.pt')\n",
    "        with open('class_descriptions.json', 'r', encoding='utf-8') as file:\n",
    "            self.class_names = json.load(file)\n",
    "\n",
    "        self.class_names += [{'id': 80+i, 'color': self.generate_random_color(), 'name': p} for i, p in enumerate(self.prompt)]\n",
    "        self.class_dict = {item['id']: item['name'] for item in self.class_names}\n",
    "        # self.dino_classes = 'pathways . trails . walkways'\n",
    "        self.dino_classes = self.enhance_class_name(self.prompt)\n",
    "        # self.dino_classes = str.join(' . ', self.prompt) + ' .'\n",
    "        self.dino_box_threshold = 0.35\n",
    "        self.dino_text_threshold = 0.25\n",
    "        self.class_descriptions = [rr.AnnotationInfo(id=cat[\"id\"], color=cat[\"color\"], label=cat[\"name\"]) for cat in self.class_names]\n",
    "        self.yolo_classes = [0, 1, 2, 3, 5, 7, 9, 11, 30]  # [0, 1, 2, 3, 5, 7, 9, 10, 11, 13, 14, 15, 16, 56, 60, 67]\n",
    "        self.persist = []\n",
    "        self.video_outs = dict()\n",
    "        \n",
    "    @staticmethod\n",
    "    def enhance_class_name(class_names: List[str]) -> List[str]:\n",
    "        return [f\"{class_name}\" for class_name in class_names]\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_random_color():\n",
    "        r = random.randint(0, 255)\n",
    "        g = random.randint(0, 255)\n",
    "        b = random.randint(0, 255)\n",
    "        return r, g, b\n",
    "    \n",
    "    def add_dino_class(self, _phrase):\n",
    "        _class_id = max(self.class_dict.keys()) + 1\n",
    "        self.class_names.append({'id': _class_id, 'color': self.generate_random_color(), 'name': _phrase})\n",
    "        self.class_dict = {item['id']: item['name'] for item in self.class_names}\n",
    "        self.class_descriptions = [rr.AnnotationInfo(id=cat[\"id\"], color=cat[\"color\"], label=cat[\"name\"]) for cat in self.class_names]\n",
    "        return _class_id\n",
    "    \n",
    "    def dino_id_to_class_name(self, dino_id):\n",
    "        return self.class_dict[dino_id]\n",
    "    \n",
    "    def phrases2classes(self, phrases: List[str]) -> (np.ndarray, bool):\n",
    "        class_ids = []\n",
    "        ret = False\n",
    "        for phrase in phrases:\n",
    "            if phrase in self.class_dict.values():\n",
    "                for k, v in self.class_dict.items():\n",
    "                    if v == phrase:\n",
    "                        class_ids.append(k)\n",
    "            else:\n",
    "                _class_id = self.add_dino_class(phrase)\n",
    "                class_ids.append(_class_id)\n",
    "                ret = True\n",
    "        return np.array(class_ids), ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8179962bc29d280d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T15:50:35.087405Z",
     "start_time": "2024-08-08T15:50:35.084035Z"
    }
   },
   "outputs": [],
   "source": [
    "GROUNDING_DINO_CONFIG_PATH = os.path.join('../', \"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\")\n",
    "GROUNDING_DINO_CHECKPOINT_PATH = os.path.join('../', \"weights\", \"groundingdino_swint_ogc.pth\")\n",
    "SAM_CHECKPOINT_PATH = os.path.join(\"/home/lnt/PycharmProjects/sam/weights/sam2_hiera_large.pt\")\n",
    "SAM_MODEL_CFG = \"sam2_hiera_l.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff04ba4269d84602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T17:38:27.349496Z",
     "start_time": "2024-08-08T17:31:19.020971Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GLAMModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m glam_model \u001b[38;5;241m=\u001b[39m \u001b[43mGLAMModel\u001b[49m(grounding_dino_config_path\u001b[38;5;241m=\u001b[39mGROUNDING_DINO_CONFIG_PATH, grounding_dino_checkpoint_path\u001b[38;5;241m=\u001b[39mGROUNDING_DINO_CHECKPOINT_PATH, sam_model_cfg\u001b[38;5;241m=\u001b[39mSAM_MODEL_CFG, sam_checkpoint_path\u001b[38;5;241m=\u001b[39mSAM_CHECKPOINT_PATH)\n\u001b[1;32m      2\u001b[0m frame_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe number\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetector\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_indoor\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GLAMModel' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "glam_model = GLAMModel(grounding_dino_config_path=GROUNDING_DINO_CONFIG_PATH, grounding_dino_checkpoint_path=GROUNDING_DINO_CHECKPOINT_PATH, sam_model_cfg=SAM_MODEL_CFG, sam_checkpoint_path=SAM_CHECKPOINT_PATH)\n",
    "frame_pos = 0\n",
    "df = pd.DataFrame([], columns=['frame number', 'detector', 'x1', 'y1', 'x2', 'y2', 'class_id', 'class_name', 'track_id', 'confidence', 'is_indoor'])\n",
    "\n",
    "HOME = '/home/lnt/PycharmProjects/sam'\n",
    "SOURCE_VIDEO_PATH = f\"{HOME}/data/world_raw.mp4\"\n",
    "output_path = f\"{HOME}/data/masks.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "is_indoor = True\n",
    "# is_indoor = False\n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "for frame_number in tqdm(range(frame_pos, total_frames)):\n",
    "    ret, frame = cap.read()\n",
    "    # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    yolo_results = glam_model.yolo.track(frame, verbose=False, conf=0.6, persist=True, retina_masks=True, classes=glam_model.yolo_classes)[0] # , classes=glam_model.yolo_classes\n",
    "    yolo_mask_frame = yolo_results.plot()\n",
    "    \n",
    "    # 使用 YOLO 结果初始化画面\n",
    "    annotated_frame = yolo_mask_frame.copy()\n",
    "    \n",
    "    if is_indoor:\n",
    "        count_chair = torch.sum((yolo_results.boxes.cls == 56) | (yolo_results.boxes.cls == 60)).item()\n",
    "        if count_chair < 1:\n",
    "            is_indoor = False\n",
    "    else:\n",
    "        count_chair = torch.sum((yolo_results.boxes.cls == 56) | (yolo_results.boxes.cls == 60)).item()\n",
    "        if count_chair > 4:\n",
    "            is_indoor = True\n",
    "\n",
    "    # dino_results = glam_model.grounding_dino_model.predict_with_classes(\n",
    "    dino_results, phrases = glam_model.grounding_dino_model.predict_with_caption(\n",
    "        image=frame,\n",
    "        caption=str.join(' . ', glam_model.prompt),\n",
    "        box_threshold=glam_model.dino_box_threshold,\n",
    "        text_threshold=glam_model.dino_text_threshold\n",
    "    )\n",
    "    dino_results.class_id, ret = glam_model.phrases2classes(phrases)\n",
    "    \n",
    "    \n",
    "    glam_model.sam_predictor.set_image(frame)\n",
    "\n",
    "    \n",
    "    for _box, _cls_id, _confidence, _phrase in zip(dino_results.xyxy, dino_results.class_id, dino_results.confidence, phrases):\n",
    "        _masks, _scores, _logits = glam_model.sam_predictor.predict(\n",
    "            box=_box,\n",
    "            multimask_output=True\n",
    "        )\n",
    "        _index = np.argmax(_scores)\n",
    "        _mask = _masks[_index]\n",
    "        _mask = _mask.astype('bool')\n",
    "        mask_result = sv.Detections(np.array([_box]), np.array([_mask]), np.array([_confidence]), np.array([_cls_id]))\n",
    "\n",
    "        mask_annotator = sv.MaskAnnotator()\n",
    "        box_annotator = sv.BoxAnnotator()\n",
    "        label_annotator = sv.LabelAnnotator(text_position=sv.Position.CENTER)\n",
    "        annotated_frame = mask_annotator.annotate(scene=annotated_frame, detections=mask_result)\n",
    "        annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=mask_result)\n",
    "        annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=mask_result, labels=[_phrase])\n",
    "    cv2.putText(annotated_frame, f'Frame: {frame_number}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "out.release()\n",
    "cap.release()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
